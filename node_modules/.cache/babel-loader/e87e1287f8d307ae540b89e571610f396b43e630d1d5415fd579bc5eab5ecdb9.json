{"ast":null,"code":"var _jsxFileName = \"/Users/kelvin/Workspace/CS180/proj2/proj2_website/proj2/src/App.js\";\nimport React from 'react';\nimport Navbar from './components/Navbar';\nimport ParentSection from './components/ParentSection';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  const parentSections = [{\n    id: 'edge-detector',\n    title: 'Edge Detection Filters',\n    sections: [{\n      id: 'derivatives-and-gradient',\n      title: 'Derivatives and Gradient',\n      content: [{\n        type: 'paragraph',\n        text: 'Inspired by the partial derivative, the finite difference filters represent the respective partial derivatives in the x and y directions. These filters can be convolved with an input image to obtain edges. Convolving an image with the Dx filter will highlight vertical edges, while convolving with the Dy filter will highlight horizontal edges.'\n      }, {\n        type: 'math',\n        text: '\\\\( \\\\frac{\\\\partial f}{\\\\partial x} = \\\\lim_{h \\\\to 0} \\\\frac{f(x+h) - f(x)}{h}, \\\\quad \\\\frac{\\\\partial f}{\\\\partial y} = \\\\lim_{h \\\\to 0} \\\\frac{f(y+h) - f(y)}{h} \\\\)'\n      }, {\n        type: 'math',\n        text: '\\\\( D_x = \\\\begin{bmatrix} 1 & -1 \\\\end{bmatrix}, \\\\quad D_y = \\\\begin{bmatrix} 1 \\\\\\\\ -1 \\\\end{bmatrix} \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'A way to capture both the horizontal and vertical edges is via the gradient magnitude. The gradient magnitude can be computed element-wise from the images filtered by Dx and Dy.'\n      }, {\n        type: 'math',\n        text: '\\\\( \\\\text{Gradient Magnitude} = \\\\sqrt{\\\\left( \\\\frac{\\\\partial f}{\\\\partial x} \\\\right)^2 + \\\\left( \\\\frac{\\\\partial f}{\\\\partial y} \\\\right)^2} \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'After obtaining the Dx-filtered, Dy-filtered, and gradient magnitude images, we can binarize them using an appropriate threshold to get a clearer edge image.'\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Original',\n          imageUrl: '/images/cameraman.png'\n        }, {\n          title: 'Dx',\n          imageUrl: '/images/binary_dx_edges.png'\n        }, {\n          title: 'Dy',\n          imageUrl: '/images/binary_dy_edges.png'\n        }, {\n          title: 'Gradient Magnitude',\n          imageUrl: '/images/binary_gradient_magnitude.png'\n        }]\n      }]\n    }, {\n      id: 'd-o-g',\n      title: 'Derivative of Gaussian',\n      content: [{\n        type: 'paragraph',\n        text: 'The results from finite difference filters are often noisy since the kernels are small and sensitive to local noise. To reduce this, the image can first be smoothed using a Gaussian kernel before applying the finite difference filters.'\n      }, {\n        type: 'paragraph',\n        text: 'From the associative property of convolution, instead of performing two separate convolutions — first with the Gaussian kernel and then with the finite difference filter — we can convolve the Gaussian kernel with the finite difference filter first, forming a derivative of Gaussian filter. Convolving the image directly with this filter produces the same result. This can be verified by asserting np.allclose() on the outputs of two separate convolutions and the single convolution with the derivative of Gaussian filter.'\n      }, {\n        type: 'math',\n        text: '\\\\((f * g) * D_x = f * (g * D_x)\\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'Convolving with the derivative of Gaussian filters produces less noisy edge images since the Gaussian blur helps even out local variations and noise. This results in an image with more distinct edges that better outline the overall structure of the input image.'\n      }, {\n        type: 'image-grid',\n        columns: 2,\n        images: [{\n          title: 'Dx of Gaussian',\n          imageUrl: '/images/dx_of_g.png'\n        }, {\n          title: 'Dy of Gaussian',\n          imageUrl: '/images/dy_of_g.png'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Smoothed Image',\n          imageUrl: '/images/blurred_cameraman.jpg'\n        }, {\n          title: 'Dx (Smoothed)',\n          imageUrl: '/images/smoothed_binary_dx_of_g.jpg'\n        }, {\n          title: 'Dy (Smoothed)',\n          imageUrl: '/images/smoothed_binary_dy_of_g.jpg'\n        }, {\n          title: 'Gradient Magnitude (Smoothed)',\n          imageUrl: '/images/smoothed_binary_gradient_magnitude_d_of_g.jpg'\n        }]\n      }]\n    }]\n  }, {\n    id: 'image-sharpening',\n    title: 'Image Sharpening Filters',\n    sections: [{\n      id: 'image-sharpening-explanation',\n      title: 'Unsharp Mask Filter',\n      content: [{\n        type: 'paragraph',\n        text: 'A technique to make an image sharper is to amplify the high-frequency components. This makes the image appear sharper because our visual perception tends to associate sharpness with stronger contrast in the fine details. Although the image appears sharper, it is a less accurate representation of the true image.'\n      }, {\n        type: 'paragraph',\n        text: 'To achieve this, we first blur the image by convolving it with a Gaussian filter. We then subtract the blurred image from the original to isolate the high-frequency components. By adding a scaled version of this high-frequency image back to the original, we obtain the sharpened result. These steps can be combined into a single convolution operation.'\n      }, {\n        type: 'math',\n        text: '\\\\( f + \\\\alpha (f - (f * g)) = f * ((1 + \\\\alpha)\\\\delta - \\\\alpha g) \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'Some examples are shown below:'\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Singapore River',\n          imageUrl: '/images/clarkequay.jpg'\n        }, {\n          title: 'Singapore River Sharpened',\n          imageUrl: '/images/clarkequay_sharp.png'\n        }, {\n          title: 'Taj Mahal',\n          imageUrl: '/images/taj.jpg'\n        }, {\n          title: 'Taj Mahal Sharpened',\n          imageUrl: '/images/taj_sharp.png'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Mount Rainier',\n          imageUrl: '/images/rainier.jpg'\n        }, {\n          title: 'Mount Rainier Sharpened',\n          imageUrl: '/images/rainier_sharp.png'\n        }, {\n          title: 'Mount Fuji',\n          imageUrl: '/images/fuji.png'\n        }, {\n          title: 'Mount Fuji Sharpened',\n          imageUrl: '/images/fuji_sharp.png'\n        }]\n      }, {\n        type: 'paragraph',\n        text: 'Here are more examples where an originally sharp image is blurred and then resharpened:'\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Palacio de Cibeles',\n          imageUrl: '/images/madrid2.jpg'\n        }, {\n          title: 'Blurred',\n          imageUrl: '/images/madrid2_blurred.png'\n        }, {\n          title: 'Resharpened',\n          imageUrl: '/images/madrid2_sharp.png'\n        }]\n      }, {\n        type: 'paragraph',\n        text: 'The resharpened image is less sharp than the original because blurring removes the highest frequency information. Resharpening the blurred image can only amplify the remaining next highest frequency information but it cannot recover the information that is lost from blurring.'\n      }]\n    }]\n  }, {\n    id: 'hybrid-images',\n    title: 'Hybrid Images',\n    sections: [{\n      id: 'human-perception',\n      title: 'Human Perception',\n      content: [{\n        type: 'paragraph',\n        text: 'Different frequencies dominate human perception based on viewing distance. When viewing an image up close, the high frequencies dominiate as we tend to observe finer details. As viewing distance increases, lower frequency features such as outlines and large shapes become more prominent.'\n      }, {\n        type: 'paragraph',\n        text: 'This gives rise to the idea of superimposing 2 images - one with high frequency elements and one with low frequency elements. This hybrid image will thus appear different based on viewing distance where the high frequency image dominates short viewing distances and the low frequency image dominates long viewing distances.'\n      }]\n    }, {\n      id: 'general-approach',\n      title: 'General Approach',\n      content: [{\n        type: 'paragraph',\n        text: 'Start with 2 images A and B. Suppose image A is the image that we want to dominate up close and image B is the one that we want to dominate from a further viewing distance. Convolve image A with a high pass filter and image B with a low pass filter. A recommended high pass filter is the impulse filter minus gaussian filer, while a recommended low pass filter is a gaussian filter. Finally, superimpose the 2 filtered images. '\n      }, {\n        type: 'math',\n        text: '\\\\(Hybrid = A * g + B * (\\\\delta - g)\\\\)'\n      }]\n    }, {\n      id: 'fourier-analysis',\n      title: 'Fourier Analysis',\n      content: [{\n        type: 'paragraph',\n        text: 'For better results, there should be a large gap (see figures below) in the fourier response of the 2 filters to prevent them interfering with one another at the low and high spatial scales. This can be done by setting lower values of sigma for the gaussian filter in the high-pass filter and high values of sigma for the gaussian filter in the low-pass filter. '\n      }, {\n        type: 'image-grid',\n        columns: 2,\n        images: [{\n          title: 'Small gap',\n          imageUrl: '/images/fourier_response_2.png'\n        }, {\n          title: 'Larger gap',\n          imageUrl: '/images/fourier_response_1.png'\n        }]\n      }, {\n        type: 'paragraph',\n        text: 'Consider the following hybrid image. Up close, it looks like a school of fish. As viewing distance increases, a more dangerous predator emerges. Up close, we observe the fine details (the small fish), while paying less attention to do background. As viewing distance increases, we are unable to observe the fine details of the fish anymore and can only observe the overall structure and outline of the image - from which we observe the outline of a shark.'\n      }, {\n        type: 'image-grid',\n        columns: 2,\n        images: [{\n          title: 'Hybrid Image',\n          imageUrl: '/images/fish_shark.jpg'\n        }, {\n          title: 'Fourier Transform (Hybrid Image)',\n          imageUrl: '/images/fft_hybrid.jpg'\n        }]\n      }, {\n        type: 'paragraph',\n        text: 'The original images used to create this hybrid image are shown below, along with their Fourier transforms. In the Fourier Transform of the hybrid image, we observe a gap in the low frequency and high frequency response.'\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Original Fish Image',\n          imageUrl: '/images/fish.jpeg'\n        }, {\n          title: 'Fourier Transform',\n          imageUrl: '/images/fft_im1.jpg'\n        }, {\n          title: 'Fourier Transform after High-pass filter',\n          imageUrl: '/images/fft_im1_highpass.jpg'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Original Shark Image',\n          imageUrl: '/images/shark.jpeg'\n        }, {\n          title: 'Fourier Transform',\n          imageUrl: '/images/fft_im2.jpg'\n        }, {\n          title: 'Fourier Transform after Low-pass filter',\n          imageUrl: '/images/fft_im2_lowpass.jpg'\n        }]\n      }, {\n        type: 'paragraph',\n        text: 'The different levels of the Laplacian stack of the hybrid image explains how the image we observe slowly changes:'\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Level 1',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_1.jpg'\n        }, {\n          title: 'Level 2',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_2.jpg'\n        }, {\n          title: 'Level 3',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_3.jpg'\n        }, {\n          title: 'Level 4',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_4.jpg'\n        }, {\n          title: 'Level 5',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_5.jpg'\n        }, {\n          title: 'Level 6',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_6.jpg'\n        }, {\n          title: 'Level 7',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_7.jpg'\n        }, {\n          title: 'Level 8',\n          imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_8.jpg'\n        }]\n      }]\n    }, {\n      id: 'optimization',\n      title: 'Optimization',\n      content: [{\n        type: 'paragraph',\n        text: 'It is important to maximize correlation between edges and promiment objects betweeen the 2 images - this means that the 2 images need to be well-aligned before trying to hybridize them. The uncorrelated should ideally appear as noise when seen from close/ far respectively.'\n      }, {\n        type: 'paragraph',\n        text: 'Color can also be used to enhance the effect. Specicially, the receptors in our eyes (cones) that are responsible for observing high frequency details are also responsible for observing color. Adding color to the high frequency image while keeping the low frequency image grayscale will enhance the dominance of the high frequency image up close. For instance, the yellow tail of the fish captures our attention and makes them more promiment up close.'\n      }, {\n        type: 'paragraph',\n        text: 'Another trick that can be used is to scale the 2 spatial channels by different factors before superimposing them. These scaling constants can be manually tuned for better performance.'\n      }, {\n        type: 'math',\n        text: '\\\\(Hybrid = \\\\alpha(A * g) + \\\\beta(B * (\\\\delta - g))\\\\)'\n      }]\n    }, {\n      id: 'results',\n      title: 'More Results',\n      content: [{\n        type: 'paragraph',\n        text: 'The images on the left are used for the high-spatial scale and the images at the center are used for the low-spatial scale. The hybrid image is on the right. Try clicking on the image and slowly walk away from the screen to observe the effect.'\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Nutmeg',\n          imageUrl: '/images/cat.png'\n        }, {\n          title: 'Derek',\n          imageUrl: '/images/derek.png'\n        }, {\n          title: 'Nutmeg-Derek',\n          imageUrl: '/images/derek_cat.jpg'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Flowers',\n          imageUrl: '/images/flowers.jpeg'\n        }, {\n          title: 'Ice Cream',\n          imageUrl: '/images/icecream.jpeg'\n        }, {\n          title: 'Flowers-IceCream',\n          imageUrl: '/images/flowericecream.jpg'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Pomeranian',\n          imageUrl: '/images/pom2.jpeg'\n        }, {\n          title: 'Bread',\n          imageUrl: '/images/bread.jpeg'\n        }, {\n          title: 'Pom-Bread',\n          imageUrl: '/images/hybrid_pom_bread.jpg'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Fish',\n          imageUrl: '/images/fish.jpeg'\n        }, {\n          title: 'Shark',\n          imageUrl: '/images/shark.jpeg'\n        }, {\n          title: 'Fish-Shark',\n          imageUrl: '/images/fish_shark.jpg'\n        }]\n      }]\n    }]\n  }, {\n    id: 'image-blending',\n    title: 'Image Blending',\n    sections: [{\n      id: 'motivation',\n      title: 'Motivation',\n      content: [{\n        type: 'paragraph',\n        text: 'A naive way to blend two images together is alpha compositing over a certain blending window.'\n      }, {\n        type: 'math',\n        text: '\\\\( I(\\\\alpha) = \\\\alpha I_{left} + (1 - \\\\alpha) I_{right} \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'A problem with this is that it is often hard to choose a good window size to avoid both ghosting and seams. To avoid ghosting, the window size needs to be less than twice the size of the smallest prominent object; to avoid seams, the window size needs to be greater than the size of the largest prominent object. In other words, good blending can only occur if the frequencies of an image are within one octave:'\n      }, {\n        type: 'math',\n        text: '\\\\( f_{max} \\\\leq 2 \\\\times f_{min} \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'Perhaps we could split the images into different frequency bands where each band is within 1 octave, perform blending on each of these bands separately, and sum up the separately blended bands to obtain the desired results'\n      }]\n    }, {\n      id: 'laplacian-stack',\n      title: 'Laplacian Stack',\n      content: [{\n        type: 'paragraph',\n        text: 'The Laplacian stack is used to capture the different levels of detail in an image. It helps in multi-resolution blending by separating the image into various frequency bands.'\n      }]\n    }, {\n      id: 'multi-resolution-blending',\n      title: 'Multi-resolution Blending',\n      content: [{\n        type: 'paragraph',\n        text: 'Multi-resolution blending is achieved by combining images across different frequency levels. We use a Laplacian stack for each image and blend them together, ensuring that both images contribute to the final result in a smooth and seamless way.'\n      }, {\n        type: 'math',\n        text: '\\\\(Blended = Laplacian(A) * Mask + Laplacian(B) * (1 - Mask)\\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'The result is a blend that looks smooth, where the transition between images is barely noticeable.'\n      }]\n    }, {\n      id: 'more-results',\n      title: 'More Results',\n      content: [{\n        type: 'paragraph',\n        text: 'Here are more examples of multi-resolution blending with different image pairs.'\n      }]\n    }]\n  }];\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"flex min-h-screen bg-gradient-to-r from-gray-900 via-gray-800 to-black text-gray-300\",\n    children: [/*#__PURE__*/_jsxDEV(Navbar, {\n      parentSections: parentSections\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 340,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"flex-1 px-4 lg:px-8 py-8 ml-64 w-full\",\n      children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n        className: \"text-4xl font-bold text-center mb-12 text-white\",\n        children: \"Image Filters\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 342,\n        columnNumber: 9\n      }, this), parentSections.map(parent => /*#__PURE__*/_jsxDEV(ParentSection, {\n        id: parent.id,\n        title: parent.title,\n        sections: parent.sections\n      }, parent.id, false, {\n        fileName: _jsxFileName,\n        lineNumber: 345,\n        columnNumber: 11\n      }, this))]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 341,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 339,\n    columnNumber: 5\n  }, this);\n}\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","Navbar","ParentSection","jsxDEV","_jsxDEV","App","parentSections","id","title","sections","content","type","text","columns","images","imageUrl","className","children","fileName","_jsxFileName","lineNumber","columnNumber","map","parent","_c","$RefreshReg$"],"sources":["/Users/kelvin/Workspace/CS180/proj2/proj2_website/proj2/src/App.js"],"sourcesContent":["import React from 'react';\nimport Navbar from './components/Navbar';\nimport ParentSection from './components/ParentSection';\n\nfunction App() {\n  const parentSections = [\n    {\n      id: 'edge-detector',\n      title: 'Edge Detection Filters',\n      sections: [\n        {\n          id: 'derivatives-and-gradient',\n          title: 'Derivatives and Gradient',\n          content: [\n            { type: 'paragraph', text: 'Inspired by the partial derivative, the finite difference filters represent the respective partial derivatives in the x and y directions. These filters can be convolved with an input image to obtain edges. Convolving an image with the Dx filter will highlight vertical edges, while convolving with the Dy filter will highlight horizontal edges.' },\n            { type: 'math', text: '\\\\( \\\\frac{\\\\partial f}{\\\\partial x} = \\\\lim_{h \\\\to 0} \\\\frac{f(x+h) - f(x)}{h}, \\\\quad \\\\frac{\\\\partial f}{\\\\partial y} = \\\\lim_{h \\\\to 0} \\\\frac{f(y+h) - f(y)}{h} \\\\)' },\n            { type: 'math', text: '\\\\( D_x = \\\\begin{bmatrix} 1 & -1 \\\\end{bmatrix}, \\\\quad D_y = \\\\begin{bmatrix} 1 \\\\\\\\ -1 \\\\end{bmatrix} \\\\)' },\n            { type: 'paragraph', text: 'A way to capture both the horizontal and vertical edges is via the gradient magnitude. The gradient magnitude can be computed element-wise from the images filtered by Dx and Dy.' },\n            { type: 'math', text: '\\\\( \\\\text{Gradient Magnitude} = \\\\sqrt{\\\\left( \\\\frac{\\\\partial f}{\\\\partial x} \\\\right)^2 + \\\\left( \\\\frac{\\\\partial f}{\\\\partial y} \\\\right)^2} \\\\)' },\n            { type: 'paragraph', text: 'After obtaining the Dx-filtered, Dy-filtered, and gradient magnitude images, we can binarize them using an appropriate threshold to get a clearer edge image.' },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Original', imageUrl: '/images/cameraman.png' },\n                { title: 'Dx', imageUrl: '/images/binary_dx_edges.png' },\n                { title: 'Dy', imageUrl: '/images/binary_dy_edges.png' },\n                { title: 'Gradient Magnitude', imageUrl: '/images/binary_gradient_magnitude.png' },\n              ],\n            },\n          ],\n        },\n        {\n          id: 'd-o-g',\n          title: 'Derivative of Gaussian',\n          content: [\n            { \n              type: 'paragraph', \n              text: 'The results from finite difference filters are often noisy since the kernels are small and sensitive to local noise. To reduce this, the image can first be smoothed using a Gaussian kernel before applying the finite difference filters.'\n            },\n            { \n              type: 'paragraph', \n              text: 'From the associative property of convolution, instead of performing two separate convolutions — first with the Gaussian kernel and then with the finite difference filter — we can convolve the Gaussian kernel with the finite difference filter first, forming a derivative of Gaussian filter. Convolving the image directly with this filter produces the same result. This can be verified by asserting np.allclose() on the outputs of two separate convolutions and the single convolution with the derivative of Gaussian filter.'\n            },\n            { \n              type: 'math', \n              text: '\\\\((f * g) * D_x = f * (g * D_x)\\\\)'\n            },\n            { \n              type: 'paragraph', \n              text: 'Convolving with the derivative of Gaussian filters produces less noisy edge images since the Gaussian blur helps even out local variations and noise. This results in an image with more distinct edges that better outline the overall structure of the input image.'\n            },\n            {\n              type: 'image-grid',\n              columns: 2,\n              images: [\n                { title: 'Dx of Gaussian', imageUrl: '/images/dx_of_g.png' },\n                { title: 'Dy of Gaussian', imageUrl: '/images/dy_of_g.png' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Smoothed Image', imageUrl: '/images/blurred_cameraman.jpg' },\n                { title: 'Dx (Smoothed)', imageUrl: '/images/smoothed_binary_dx_of_g.jpg' },\n                { title: 'Dy (Smoothed)', imageUrl: '/images/smoothed_binary_dy_of_g.jpg' },\n                { title: 'Gradient Magnitude (Smoothed)', imageUrl: '/images/smoothed_binary_gradient_magnitude_d_of_g.jpg' },\n              ],\n            },\n          ],\n        },\n      ],\n    },\n    {\n      id: 'image-sharpening',\n      title: 'Image Sharpening Filters',\n      sections: [\n        {\n          id: 'image-sharpening-explanation',\n          title: 'Unsharp Mask Filter',\n          content: [\n            { \n              type: 'paragraph', \n              text: 'A technique to make an image sharper is to amplify the high-frequency components. This makes the image appear sharper because our visual perception tends to associate sharpness with stronger contrast in the fine details. Although the image appears sharper, it is a less accurate representation of the true image.'\n            },\n            { \n              type: 'paragraph', \n              text: 'To achieve this, we first blur the image by convolving it with a Gaussian filter. We then subtract the blurred image from the original to isolate the high-frequency components. By adding a scaled version of this high-frequency image back to the original, we obtain the sharpened result. These steps can be combined into a single convolution operation.'\n            },\n            { \n              type: 'math', \n              text: '\\\\( f + \\\\alpha (f - (f * g)) = f * ((1 + \\\\alpha)\\\\delta - \\\\alpha g) \\\\)'\n            },\n            { \n              type: 'paragraph', \n              text: 'Some examples are shown below:'\n            },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Singapore River', imageUrl: '/images/clarkequay.jpg' },\n                { title: 'Singapore River Sharpened', imageUrl: '/images/clarkequay_sharp.png' },\n                { title: 'Taj Mahal', imageUrl: '/images/taj.jpg' },\n                { title: 'Taj Mahal Sharpened', imageUrl: '/images/taj_sharp.png' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Mount Rainier', imageUrl: '/images/rainier.jpg' },\n                { title: 'Mount Rainier Sharpened', imageUrl: '/images/rainier_sharp.png' },\n                { title: 'Mount Fuji', imageUrl: '/images/fuji.png' },\n                { title: 'Mount Fuji Sharpened', imageUrl: '/images/fuji_sharp.png' },\n              ],\n            },\n            { \n              type: 'paragraph', \n              text: 'Here are more examples where an originally sharp image is blurred and then resharpened:'\n            },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Palacio de Cibeles', imageUrl: '/images/madrid2.jpg' },\n                { title: 'Blurred', imageUrl: '/images/madrid2_blurred.png' },\n                { title: 'Resharpened', imageUrl: '/images/madrid2_sharp.png' },\n              ],\n            },\n            { \n              type: 'paragraph', \n              text: 'The resharpened image is less sharp than the original because blurring removes the highest frequency information. Resharpening the blurred image can only amplify the remaining next highest frequency information but it cannot recover the information that is lost from blurring.'\n            },\n          ],\n        },\n      ],\n    },\n    {\n      id: 'hybrid-images',\n      title: 'Hybrid Images',\n      sections: [\n        {\n          id: 'human-perception',\n          title: 'Human Perception',\n          content: [\n            { type: 'paragraph', text: 'Different frequencies dominate human perception based on viewing distance. When viewing an image up close, the high frequencies dominiate as we tend to observe finer details. As viewing distance increases, lower frequency features such as outlines and large shapes become more prominent.' },\n            { type: 'paragraph', text: 'This gives rise to the idea of superimposing 2 images - one with high frequency elements and one with low frequency elements. This hybrid image will thus appear different based on viewing distance where the high frequency image dominates short viewing distances and the low frequency image dominates long viewing distances.' },\n          ],\n        },\n        {\n          id: 'general-approach',\n          title: 'General Approach',\n          content: [\n            { type: 'paragraph', text: 'Start with 2 images A and B. Suppose image A is the image that we want to dominate up close and image B is the one that we want to dominate from a further viewing distance. Convolve image A with a high pass filter and image B with a low pass filter. A recommended high pass filter is the impulse filter minus gaussian filer, while a recommended low pass filter is a gaussian filter. Finally, superimpose the 2 filtered images. ' },\n            {\n              type: 'math', \n              text: '\\\\(Hybrid = A * g + B * (\\\\delta - g)\\\\)'\n            }\n          ],\n        },\n        {\n          id: 'fourier-analysis',\n          title: 'Fourier Analysis',\n          content: [\n            { type: 'paragraph', text: 'For better results, there should be a large gap (see figures below) in the fourier response of the 2 filters to prevent them interfering with one another at the low and high spatial scales. This can be done by setting lower values of sigma for the gaussian filter in the high-pass filter and high values of sigma for the gaussian filter in the low-pass filter. ' },\n            {\n              type: 'image-grid',\n              columns: 2,\n              images: [\n                { title: 'Small gap', imageUrl: '/images/fourier_response_2.png' },\n                { title: 'Larger gap', imageUrl: '/images/fourier_response_1.png' },\n              ],\n            },\n            { type: 'paragraph', text: 'Consider the following hybrid image. Up close, it looks like a school of fish. As viewing distance increases, a more dangerous predator emerges. Up close, we observe the fine details (the small fish), while paying less attention to do background. As viewing distance increases, we are unable to observe the fine details of the fish anymore and can only observe the overall structure and outline of the image - from which we observe the outline of a shark.' },\n            {\n              type: 'image-grid',\n              columns: 2,\n              images: [\n                { title: 'Hybrid Image', imageUrl: '/images/fish_shark.jpg' },\n                { title: 'Fourier Transform (Hybrid Image)', imageUrl: '/images/fft_hybrid.jpg' },\n              ],\n            },\n            { type: 'paragraph', text: 'The original images used to create this hybrid image are shown below, along with their Fourier transforms. In the Fourier Transform of the hybrid image, we observe a gap in the low frequency and high frequency response.' },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Original Fish Image', imageUrl: '/images/fish.jpeg' },\n                { title: 'Fourier Transform', imageUrl: '/images/fft_im1.jpg' },\n                { title: 'Fourier Transform after High-pass filter', imageUrl: '/images/fft_im1_highpass.jpg' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Original Shark Image', imageUrl: '/images/shark.jpeg' },\n                { title: 'Fourier Transform', imageUrl: '/images/fft_im2.jpg' },\n                { title: 'Fourier Transform after Low-pass filter', imageUrl: '/images/fft_im2_lowpass.jpg' },\n              ],\n            },\n            { type: 'paragraph', text: 'The different levels of the Laplacian stack of the hybrid image explains how the image we observe slowly changes:' },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Level 1', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_1.jpg' },\n                { title: 'Level 2', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_2.jpg' },\n                { title: 'Level 3', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_3.jpg' },\n                { title: 'Level 4', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_4.jpg' },\n                { title: 'Level 5', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_5.jpg' },\n                { title: 'Level 6', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_6.jpg' },\n                { title: 'Level 7', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_7.jpg' },\n                { title: 'Level 8', imageUrl: '/images/laplacian_stack_hybrid/hybrid_laplacian_level_8.jpg' },\n              ],\n            },\n          ],\n        },\n        {\n          id: 'optimization',\n          title: 'Optimization',\n          content: [\n            { type: 'paragraph', text: 'It is important to maximize correlation between edges and promiment objects betweeen the 2 images - this means that the 2 images need to be well-aligned before trying to hybridize them. The uncorrelated should ideally appear as noise when seen from close/ far respectively.' },\n            { type: 'paragraph', text: 'Color can also be used to enhance the effect. Specicially, the receptors in our eyes (cones) that are responsible for observing high frequency details are also responsible for observing color. Adding color to the high frequency image while keeping the low frequency image grayscale will enhance the dominance of the high frequency image up close. For instance, the yellow tail of the fish captures our attention and makes them more promiment up close.'},\n            { type: 'paragraph', text: 'Another trick that can be used is to scale the 2 spatial channels by different factors before superimposing them. These scaling constants can be manually tuned for better performance.'},\n            {\n              type: 'math', \n              text: '\\\\(Hybrid = \\\\alpha(A * g) + \\\\beta(B * (\\\\delta - g))\\\\)'\n            }\n          ],\n        },\n        {\n          id: 'results',\n          title: 'More Results',\n          content: [\n            { type: 'paragraph', text: 'The images on the left are used for the high-spatial scale and the images at the center are used for the low-spatial scale. The hybrid image is on the right. Try clicking on the image and slowly walk away from the screen to observe the effect.' },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Nutmeg', imageUrl: '/images/cat.png' },\n                { title: 'Derek', imageUrl: '/images/derek.png' },\n                { title: 'Nutmeg-Derek', imageUrl: '/images/derek_cat.jpg' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Flowers', imageUrl: '/images/flowers.jpeg' },\n                { title: 'Ice Cream', imageUrl: '/images/icecream.jpeg' },\n                { title: 'Flowers-IceCream', imageUrl: '/images/flowericecream.jpg' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Pomeranian', imageUrl: '/images/pom2.jpeg' },\n                { title: 'Bread', imageUrl: '/images/bread.jpeg' },\n                { title: 'Pom-Bread', imageUrl: '/images/hybrid_pom_bread.jpg' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Fish', imageUrl: '/images/fish.jpeg' },\n                { title: 'Shark', imageUrl: '/images/shark.jpeg' },\n                { title: 'Fish-Shark', imageUrl: '/images/fish_shark.jpg' },\n              ],\n            },\n          ],\n        },\n      ],\n    },\n    {\n      id: 'image-blending',\n      title: 'Image Blending',\n      sections: [\n        {\n          id: 'motivation',\n          title: 'Motivation',\n          content: [\n            { \n              type: 'paragraph', \n              text: 'A naive way to blend two images together is alpha compositing over a certain blending window.' \n            },\n            { \n              type: 'math', \n              text: '\\\\( I(\\\\alpha) = \\\\alpha I_{left} + (1 - \\\\alpha) I_{right} \\\\)' \n            },\n            { \n              type: 'paragraph', \n              text: 'A problem with this is that it is often hard to choose a good window size to avoid both ghosting and seams. To avoid ghosting, the window size needs to be less than twice the size of the smallest prominent object; to avoid seams, the window size needs to be greater than the size of the largest prominent object. In other words, good blending can only occur if the frequencies of an image are within one octave:' \n            },\n            { \n              type: 'math', \n              text: '\\\\( f_{max} \\\\leq 2 \\\\times f_{min} \\\\)' \n            },\n            {\n              type: 'paragraph', \n              text: 'Perhaps we could split the images into different frequency bands where each band is within 1 octave, perform blending on each of these bands separately, and sum up the separately blended bands to obtain the desired results'\n            }\n          ]          \n        },\n        {\n          id: 'laplacian-stack',\n          title: 'Laplacian Stack',\n          content: [\n            { type: 'paragraph', text: 'The Laplacian stack is used to capture the different levels of detail in an image. It helps in multi-resolution blending by separating the image into various frequency bands.' },\n          ],\n        },\n        {\n          id: 'multi-resolution-blending',\n          title: 'Multi-resolution Blending',\n          content: [\n            { type: 'paragraph', text: 'Multi-resolution blending is achieved by combining images across different frequency levels. We use a Laplacian stack for each image and blend them together, ensuring that both images contribute to the final result in a smooth and seamless way.' },\n            {\n              type: 'math',\n              text: '\\\\(Blended = Laplacian(A) * Mask + Laplacian(B) * (1 - Mask)\\\\)',\n            },\n            { type: 'paragraph', text: 'The result is a blend that looks smooth, where the transition between images is barely noticeable.' },\n          ],\n        },\n        {\n          id: 'more-results',\n          title: 'More Results',\n          content: [\n            { type: 'paragraph', text: 'Here are more examples of multi-resolution blending with different image pairs.' },\n          ],\n        },\n      ],\n    },    \n  ];\n  return (\n    <div className=\"flex min-h-screen bg-gradient-to-r from-gray-900 via-gray-800 to-black text-gray-300\">\n      <Navbar parentSections={parentSections} />\n      <div className=\"flex-1 px-4 lg:px-8 py-8 ml-64 w-full\">\n        <h1 className=\"text-4xl font-bold text-center mb-12 text-white\">Image Filters</h1>\n\n        {parentSections.map((parent) => (\n          <ParentSection\n            key={parent.id}\n            id={parent.id}\n            title={parent.title}\n            sections={parent.sections}\n          />\n        ))}\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,MAAM,MAAM,qBAAqB;AACxC,OAAOC,aAAa,MAAM,4BAA4B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvD,SAASC,GAAGA,CAAA,EAAG;EACb,MAAMC,cAAc,GAAG,CACrB;IACEC,EAAE,EAAE,eAAe;IACnBC,KAAK,EAAE,wBAAwB;IAC/BC,QAAQ,EAAE,CACR;MACEF,EAAE,EAAE,0BAA0B;MAC9BC,KAAK,EAAE,0BAA0B;MACjCE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA2V,CAAC,EACvX;QAAED,IAAI,EAAE,MAAM;QAAEC,IAAI,EAAE;MAA4K,CAAC,EACnM;QAAED,IAAI,EAAE,MAAM;QAAEC,IAAI,EAAE;MAA+G,CAAC,EACtI;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAoL,CAAC,EAChN;QAAED,IAAI,EAAE,MAAM;QAAEC,IAAI,EAAE;MAAyJ,CAAC,EAChL;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAgK,CAAC,EAC5L;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,UAAU;UAAEO,QAAQ,EAAE;QAAwB,CAAC,EACxD;UAAEP,KAAK,EAAE,IAAI;UAAEO,QAAQ,EAAE;QAA8B,CAAC,EACxD;UAAEP,KAAK,EAAE,IAAI;UAAEO,QAAQ,EAAE;QAA8B,CAAC,EACxD;UAAEP,KAAK,EAAE,oBAAoB;UAAEO,QAAQ,EAAE;QAAwC,CAAC;MAEtF,CAAC;IAEL,CAAC,EACD;MACER,EAAE,EAAE,OAAO;MACXC,KAAK,EAAE,wBAAwB;MAC/BE,OAAO,EAAE,CACP;QACEC,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,gBAAgB;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAC5D;UAAEP,KAAK,EAAE,gBAAgB;UAAEO,QAAQ,EAAE;QAAsB,CAAC;MAEhE,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,gBAAgB;UAAEO,QAAQ,EAAE;QAAgC,CAAC,EACtE;UAAEP,KAAK,EAAE,eAAe;UAAEO,QAAQ,EAAE;QAAsC,CAAC,EAC3E;UAAEP,KAAK,EAAE,eAAe;UAAEO,QAAQ,EAAE;QAAsC,CAAC,EAC3E;UAAEP,KAAK,EAAE,+BAA+B;UAAEO,QAAQ,EAAE;QAAwD,CAAC;MAEjH,CAAC;IAEL,CAAC;EAEL,CAAC,EACD;IACER,EAAE,EAAE,kBAAkB;IACtBC,KAAK,EAAE,0BAA0B;IACjCC,QAAQ,EAAE,CACR;MACEF,EAAE,EAAE,8BAA8B;MAClCC,KAAK,EAAE,qBAAqB;MAC5BE,OAAO,EAAE,CACP;QACEC,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,iBAAiB;UAAEO,QAAQ,EAAE;QAAyB,CAAC,EAChE;UAAEP,KAAK,EAAE,2BAA2B;UAAEO,QAAQ,EAAE;QAA+B,CAAC,EAChF;UAAEP,KAAK,EAAE,WAAW;UAAEO,QAAQ,EAAE;QAAkB,CAAC,EACnD;UAAEP,KAAK,EAAE,qBAAqB;UAAEO,QAAQ,EAAE;QAAwB,CAAC;MAEvE,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,eAAe;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAC3D;UAAEP,KAAK,EAAE,yBAAyB;UAAEO,QAAQ,EAAE;QAA4B,CAAC,EAC3E;UAAEP,KAAK,EAAE,YAAY;UAAEO,QAAQ,EAAE;QAAmB,CAAC,EACrD;UAAEP,KAAK,EAAE,sBAAsB;UAAEO,QAAQ,EAAE;QAAyB,CAAC;MAEzE,CAAC,EACD;QACEJ,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,oBAAoB;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAChE;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8B,CAAC,EAC7D;UAAEP,KAAK,EAAE,aAAa;UAAEO,QAAQ,EAAE;QAA4B,CAAC;MAEnE,CAAC,EACD;QACEJ,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC;IAEL,CAAC;EAEL,CAAC,EACD;IACEL,EAAE,EAAE,eAAe;IACnBC,KAAK,EAAE,eAAe;IACtBC,QAAQ,EAAE,CACR;MACEF,EAAE,EAAE,kBAAkB;MACtBC,KAAK,EAAE,kBAAkB;MACzBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAkS,CAAC,EAC9T;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAsU,CAAC;IAEtW,CAAC,EACD;MACEL,EAAE,EAAE,kBAAkB;MACtBC,KAAK,EAAE,kBAAkB;MACzBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA8a,CAAC,EAC1c;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC;IAEL,CAAC,EACD;MACEL,EAAE,EAAE,kBAAkB;MACtBC,KAAK,EAAE,kBAAkB;MACzBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA4W,CAAC,EACxY;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,WAAW;UAAEO,QAAQ,EAAE;QAAiC,CAAC,EAClE;UAAEP,KAAK,EAAE,YAAY;UAAEO,QAAQ,EAAE;QAAiC,CAAC;MAEvE,CAAC,EACD;QAAEJ,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA0c,CAAC,EACte;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,cAAc;UAAEO,QAAQ,EAAE;QAAyB,CAAC,EAC7D;UAAEP,KAAK,EAAE,kCAAkC;UAAEO,QAAQ,EAAE;QAAyB,CAAC;MAErF,CAAC,EACD;QAAEJ,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA8N,CAAC,EAC1P;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,qBAAqB;UAAEO,QAAQ,EAAE;QAAoB,CAAC,EAC/D;UAAEP,KAAK,EAAE,mBAAmB;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAC/D;UAAEP,KAAK,EAAE,0CAA0C;UAAEO,QAAQ,EAAE;QAA+B,CAAC;MAEnG,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,sBAAsB;UAAEO,QAAQ,EAAE;QAAqB,CAAC,EACjE;UAAEP,KAAK,EAAE,mBAAmB;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAC/D;UAAEP,KAAK,EAAE,yCAAyC;UAAEO,QAAQ,EAAE;QAA8B,CAAC;MAEjG,CAAC,EACD;QAAEJ,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAoH,CAAC,EAChJ;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC,EAC7F;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC,EAC7F;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC,EAC7F;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC,EAC7F;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC,EAC7F;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC,EAC7F;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC,EAC7F;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8D,CAAC;MAEjG,CAAC;IAEL,CAAC,EACD;MACER,EAAE,EAAE,cAAc;MAClBC,KAAK,EAAE,cAAc;MACrBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAoR,CAAC,EAChT;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAqc,CAAC,EACje;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAyL,CAAC,EACrN;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC;IAEL,CAAC,EACD;MACEL,EAAE,EAAE,SAAS;MACbC,KAAK,EAAE,cAAc;MACrBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAsP,CAAC,EAClR;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,QAAQ;UAAEO,QAAQ,EAAE;QAAkB,CAAC,EAChD;UAAEP,KAAK,EAAE,OAAO;UAAEO,QAAQ,EAAE;QAAoB,CAAC,EACjD;UAAEP,KAAK,EAAE,cAAc;UAAEO,QAAQ,EAAE;QAAwB,CAAC;MAEhE,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAAuB,CAAC,EACtD;UAAEP,KAAK,EAAE,WAAW;UAAEO,QAAQ,EAAE;QAAwB,CAAC,EACzD;UAAEP,KAAK,EAAE,kBAAkB;UAAEO,QAAQ,EAAE;QAA6B,CAAC;MAEzE,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,YAAY;UAAEO,QAAQ,EAAE;QAAoB,CAAC,EACtD;UAAEP,KAAK,EAAE,OAAO;UAAEO,QAAQ,EAAE;QAAqB,CAAC,EAClD;UAAEP,KAAK,EAAE,WAAW;UAAEO,QAAQ,EAAE;QAA+B,CAAC;MAEpE,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,MAAM;UAAEO,QAAQ,EAAE;QAAoB,CAAC,EAChD;UAAEP,KAAK,EAAE,OAAO;UAAEO,QAAQ,EAAE;QAAqB,CAAC,EAClD;UAAEP,KAAK,EAAE,YAAY;UAAEO,QAAQ,EAAE;QAAyB,CAAC;MAE/D,CAAC;IAEL,CAAC;EAEL,CAAC,EACD;IACER,EAAE,EAAE,gBAAgB;IACpBC,KAAK,EAAE,gBAAgB;IACvBC,QAAQ,EAAE,CACR;MACEF,EAAE,EAAE,YAAY;MAChBC,KAAK,EAAE,YAAY;MACnBE,OAAO,EAAE,CACP;QACEC,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC;IAEL,CAAC,EACD;MACEL,EAAE,EAAE,iBAAiB;MACrBC,KAAK,EAAE,iBAAiB;MACxBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAiL,CAAC;IAEjN,CAAC,EACD;MACEL,EAAE,EAAE,2BAA2B;MAC/BC,KAAK,EAAE,2BAA2B;MAClCE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAuP,CAAC,EACnR;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC,EACD;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAqG,CAAC;IAErI,CAAC,EACD;MACEL,EAAE,EAAE,cAAc;MAClBC,KAAK,EAAE,cAAc;MACrBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAkF,CAAC;IAElH,CAAC;EAEL,CAAC,CACF;EACD,oBACER,OAAA;IAAKY,SAAS,EAAC,sFAAsF;IAAAC,QAAA,gBACnGb,OAAA,CAACH,MAAM;MAACK,cAAc,EAAEA;IAAe;MAAAY,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eAC1CjB,OAAA;MAAKY,SAAS,EAAC,uCAAuC;MAAAC,QAAA,gBACpDb,OAAA;QAAIY,SAAS,EAAC,iDAAiD;QAAAC,QAAA,EAAC;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,EAEjFf,cAAc,CAACgB,GAAG,CAAEC,MAAM,iBACzBnB,OAAA,CAACF,aAAa;QAEZK,EAAE,EAAEgB,MAAM,CAAChB,EAAG;QACdC,KAAK,EAAEe,MAAM,CAACf,KAAM;QACpBC,QAAQ,EAAEc,MAAM,CAACd;MAAS,GAHrBc,MAAM,CAAChB,EAAE;QAAAW,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAIf,CACF,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV;AAACG,EAAA,GA9VQnB,GAAG;AAgWZ,eAAeA,GAAG;AAAC,IAAAmB,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}