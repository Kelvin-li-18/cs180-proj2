{"ast":null,"code":"var _jsxFileName = \"/Users/kelvin/Workspace/CS180/proj2/proj2_website/proj2/src/App.js\";\nimport React from 'react';\nimport Navbar from './components/Navbar';\nimport ParentSection from './components/ParentSection';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  const parentSections = [{\n    id: 'edge-detector',\n    title: 'Edge Detection Filters',\n    sections: [{\n      id: 'derivatives-and-gradient',\n      title: 'Derivatives and Gradient',\n      content: [{\n        type: 'paragraph',\n        text: 'Inspired by the partial derivative, the finite difference filters represent the respective partial derivatives in the x and y directions. These filters can be convolved with an input image to obtain edges. Convolving an image with the Dx filter will highlight vertical edges, while convolving with the Dy filter will highlight horizontal edges.'\n      }, {\n        type: 'math',\n        text: '\\\\( \\\\frac{\\\\partial f}{\\\\partial x} = \\\\lim_{h \\\\to 0} \\\\frac{f(x+h) - f(x)}{h}, \\\\quad \\\\frac{\\\\partial f}{\\\\partial y} = \\\\lim_{h \\\\to 0} \\\\frac{f(y+h) - f(y)}{h} \\\\)'\n      }, {\n        type: 'math',\n        text: '\\\\( D_x = \\\\begin{bmatrix} 1 & -1 \\\\end{bmatrix}, \\\\quad D_y = \\\\begin{bmatrix} 1 \\\\\\\\ -1 \\\\end{bmatrix} \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'A way to capture both the horizontal and vertical edges is via the gradient magnitude. The gradient magnitude can be computed element-wise from the images filtered by Dx and Dy.'\n      }, {\n        type: 'math',\n        text: '\\\\( \\\\text{Gradient Magnitude} = \\\\sqrt{\\\\left( \\\\frac{\\\\partial f}{\\\\partial x} \\\\right)^2 + \\\\left( \\\\frac{\\\\partial f}{\\\\partial y} \\\\right)^2} \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'After obtaining the Dx-filtered, Dy-filtered, and gradient magnitude images, we can binarize them using an appropriate threshold to get a clearer edge image.'\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Original',\n          imageUrl: '/images/cameraman.png'\n        }, {\n          title: 'Dx',\n          imageUrl: '/images/binary_dx_edges.png'\n        }, {\n          title: 'Dy',\n          imageUrl: '/images/binary_dy_edges.png'\n        }, {\n          title: 'Gradient Magnitude',\n          imageUrl: '/images/binary_gradient_magnitude.png'\n        }]\n      }]\n    }, {\n      id: 'd-o-g',\n      title: 'Derivative of Gaussian',\n      content: [{\n        type: 'paragraph',\n        text: 'The results from finite difference filters are often noisy since the kernels are small and sensitive to local noise. To reduce this, the image can first be smoothed using a Gaussian kernel before applying the finite difference filters.'\n      }, {\n        type: 'paragraph',\n        text: 'From the associative property of convolution, instead of performing two separate convolutions — first with the Gaussian kernel and then with the finite difference filter — we can convolve the Gaussian kernel with the finite difference filter first, forming a derivative of Gaussian filter. Convolving the image directly with this filter produces the same result. This can be verified by asserting np.allclose() on the outputs of two separate convolutions and the single convolution with the derivative of Gaussian filter.'\n      }, {\n        type: 'math',\n        text: '\\\\((f * g) * D_x = f * (g * D_x)\\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'Convolving with the derivative of Gaussian filters produces less noisy edge images since the Gaussian blur helps even out local variations and noise. This results in an image with more distinct edges that better outline the overall structure of the input image.'\n      }, {\n        type: 'image-grid',\n        columns: 2,\n        images: [{\n          title: 'Dx of Gaussian',\n          imageUrl: '/images/dx_of_g.png'\n        }, {\n          title: 'Dy of Gaussian',\n          imageUrl: '/images/dy_of_g.png'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Smoothed Image',\n          imageUrl: '/images/blurred_cameraman.jpg'\n        }, {\n          title: 'Dx (Smoothed)',\n          imageUrl: '/images/smoothed_binary_dx_of_g.jpg'\n        }, {\n          title: 'Dy (Smoothed)',\n          imageUrl: '/images/smoothed_binary_dy_of_g.jpg'\n        }, {\n          title: 'Gradient Magnitude (Smoothed)',\n          imageUrl: '/images/smoothed_binary_gradient_magnitude_d_of_g.jpg'\n        }]\n      }]\n    }]\n  }, {\n    id: 'image-sharpening',\n    title: 'Image Sharpening Filters',\n    sections: [{\n      id: 'image-sharpening-explanation',\n      title: 'Unsharp Mask Filter',\n      content: [{\n        type: 'paragraph',\n        text: 'A technique to make an image sharper is to amplify the high-frequency components. This makes the image appear sharper because our visual perception tends to associate sharpness with stronger contrast in the fine details. Although the image appears sharper, it is a less accurate representation of the true image.'\n      }, {\n        type: 'paragraph',\n        text: 'To achieve this, we first blur the image by convolving it with a Gaussian filter. We then subtract the blurred image from the original to isolate the high-frequency components. By adding a scaled version of this high-frequency image back to the original, we obtain the sharpened result. These steps can be combined into a single convolution operation.'\n      }, {\n        type: 'math',\n        text: '\\\\( f + \\\\alpha (f - (f * g)) = f * ((1 + \\\\alpha)\\\\delta - \\\\alpha h) \\\\)'\n      }, {\n        type: 'paragraph',\n        text: 'Some examples are shown below:'\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Singapore River',\n          imageUrl: '/images/clarkequay.jpg'\n        }, {\n          title: 'Singapore River Sharpened',\n          imageUrl: '/images/clarkequay_sharp.png'\n        }, {\n          title: 'Taj Mahal',\n          imageUrl: '/images/taj.jpg'\n        }, {\n          title: 'Taj Mahal Sharpened',\n          imageUrl: '/images/taj_sharp.png'\n        }]\n      }, {\n        type: 'image-grid',\n        columns: 4,\n        images: [{\n          title: 'Mount Rainier',\n          imageUrl: '/images/rainier.jpg'\n        }, {\n          title: 'Mount Rainier Sharpened',\n          imageUrl: '/images/rainier_sharp.png'\n        }, {\n          title: 'Mount Fuji',\n          imageUrl: '/images/fuji.png'\n        }, {\n          title: 'Mount Fuji Sharpened',\n          imageUrl: '/images/fuji_sharp.png'\n        }]\n      }, {\n        type: 'paragraph',\n        text: 'Here are more examples where an originally sharp image is blurred and then resharpened:'\n      }, {\n        type: 'image-grid',\n        columns: 3,\n        images: [{\n          title: 'Palacio de Cibeles',\n          imageUrl: '/images/madrid2.jpg'\n        }, {\n          title: 'Blurred',\n          imageUrl: '/images/madrid2_blurred.png'\n        }, {\n          title: 'Resharpened',\n          imageUrl: '/images/madrid2_sharp.png'\n        }]\n      }, {\n        type: 'paragraph',\n        text: 'The resharpened image is less sharp than the original because blurring removes the highest frequency information. Resharpening the blurred image can only amplify the remaining next highest frequency information but it cannot recover the information that is lost from blurring.'\n      }]\n    }]\n  }, {\n    id: 'hybrid-images',\n    title: 'Hybrid Images',\n    sections: [{\n      id: 'human-perception',\n      title: 'Human Perception',\n      content: [{\n        type: 'paragraph',\n        text: 'Different frequencies dominate human perception based on viewing distance. When viewing an image up close, the high frequencies dominiate as we tend to observe finer details. As viewing distance increases, lower frequency features such as outlines and large shapes become more prominent.'\n      }, {\n        type: 'paragraph',\n        text: 'This gives rise to the idea of superimposing 2 images - one with high frequency elements and one with low frequency elements. This hybrid image will thus appear different based on viewing distance where the high frequency image dominates short viewing distances and the low frequency image dominates long viewing distances.'\n      }]\n    }, {\n      id: 'general-approach',\n      title: 'General Approach',\n      content: [{\n        type: 'paragraph',\n        text: 'Start with 2 images A and B. Suppose image A is the image that we want to dominate up close and image B is the one that we want to dominate from a further viewing distance. Convolve image A with a high pass filter and image B with a low pass filter. A recommended high pass filter is the impulse filter minus gaussian filer, while a recommended low pass filter is a gaussian filter. Finally, superimpose the 2 filtered images. '\n      }, {\n        type: 'math',\n        text: '\\\\(Hybrid = A * g + B * (\\\\delta - g)\\\\)'\n      }]\n    }, {\n      id: 'optimization',\n      title: 'Optimization',\n      content: [{\n        type: 'paragraph',\n        text: 'It is important to maximize correlation between edges and promiment objects betweeen the 2 images - this means that the 2 images need to be well-aligned before trying to hybridize them. The uncorrelated should ideally appear as noise when seen from close/ far respectively.'\n      }, {\n        type: 'paragraph',\n        text: 'Color can also be used to enhance the effect. Specicially, the receptors in our eyes (cones) that are responsible for observing high frequency details are also responsible for observing color. Adding color to the high frequency image while keeping the low frequency image grayscale will enhance the dominance of the high frequency image up close.'\n      }]\n    }, {\n      id: 'fourier-analysis',\n      title: 'Fourier Analysis',\n      content: [{\n        type: 'paragraph',\n        text: 'For better results, there should be a gap in the fourier response of the 2 filters to prevent them interfering with one another at the low and high spatial scales.'\n      }]\n    }, {\n      id: 'results',\n      title: 'Results',\n      content: [{\n        type: 'paragraph',\n        text: 'Content for Results section...'\n      }\n      // Additional content...\n      ]\n    }]\n  }];\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"flex min-h-screen bg-gradient-to-r from-gray-900 via-gray-800 to-black text-gray-300\",\n    children: [/*#__PURE__*/_jsxDEV(Navbar, {\n      parentSections: parentSections\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 191,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"flex-1 px-4 lg:px-8 py-8 ml-64 w-full\",\n      children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n        className: \"text-4xl font-bold text-center mb-12 text-white\",\n        children: \"Image Filters\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 193,\n        columnNumber: 9\n      }, this), parentSections.map(parent => /*#__PURE__*/_jsxDEV(ParentSection, {\n        id: parent.id,\n        title: parent.title,\n        sections: parent.sections\n      }, parent.id, false, {\n        fileName: _jsxFileName,\n        lineNumber: 196,\n        columnNumber: 11\n      }, this))]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 192,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 190,\n    columnNumber: 5\n  }, this);\n}\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","Navbar","ParentSection","jsxDEV","_jsxDEV","App","parentSections","id","title","sections","content","type","text","columns","images","imageUrl","className","children","fileName","_jsxFileName","lineNumber","columnNumber","map","parent","_c","$RefreshReg$"],"sources":["/Users/kelvin/Workspace/CS180/proj2/proj2_website/proj2/src/App.js"],"sourcesContent":["import React from 'react';\nimport Navbar from './components/Navbar';\nimport ParentSection from './components/ParentSection';\n\nfunction App() {\n  const parentSections = [\n    {\n      id: 'edge-detector',\n      title: 'Edge Detection Filters',\n      sections: [\n        {\n          id: 'derivatives-and-gradient',\n          title: 'Derivatives and Gradient',\n          content: [\n            { type: 'paragraph', text: 'Inspired by the partial derivative, the finite difference filters represent the respective partial derivatives in the x and y directions. These filters can be convolved with an input image to obtain edges. Convolving an image with the Dx filter will highlight vertical edges, while convolving with the Dy filter will highlight horizontal edges.' },\n            { type: 'math', text: '\\\\( \\\\frac{\\\\partial f}{\\\\partial x} = \\\\lim_{h \\\\to 0} \\\\frac{f(x+h) - f(x)}{h}, \\\\quad \\\\frac{\\\\partial f}{\\\\partial y} = \\\\lim_{h \\\\to 0} \\\\frac{f(y+h) - f(y)}{h} \\\\)' },\n            { type: 'math', text: '\\\\( D_x = \\\\begin{bmatrix} 1 & -1 \\\\end{bmatrix}, \\\\quad D_y = \\\\begin{bmatrix} 1 \\\\\\\\ -1 \\\\end{bmatrix} \\\\)' },\n            { type: 'paragraph', text: 'A way to capture both the horizontal and vertical edges is via the gradient magnitude. The gradient magnitude can be computed element-wise from the images filtered by Dx and Dy.' },\n            { type: 'math', text: '\\\\( \\\\text{Gradient Magnitude} = \\\\sqrt{\\\\left( \\\\frac{\\\\partial f}{\\\\partial x} \\\\right)^2 + \\\\left( \\\\frac{\\\\partial f}{\\\\partial y} \\\\right)^2} \\\\)' },\n            { type: 'paragraph', text: 'After obtaining the Dx-filtered, Dy-filtered, and gradient magnitude images, we can binarize them using an appropriate threshold to get a clearer edge image.' },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Original', imageUrl: '/images/cameraman.png' },\n                { title: 'Dx', imageUrl: '/images/binary_dx_edges.png' },\n                { title: 'Dy', imageUrl: '/images/binary_dy_edges.png' },\n                { title: 'Gradient Magnitude', imageUrl: '/images/binary_gradient_magnitude.png' },\n              ],\n            },\n          ],\n        },\n        {\n          id: 'd-o-g',\n          title: 'Derivative of Gaussian',\n          content: [\n            { \n              type: 'paragraph', \n              text: 'The results from finite difference filters are often noisy since the kernels are small and sensitive to local noise. To reduce this, the image can first be smoothed using a Gaussian kernel before applying the finite difference filters.'\n            },\n            { \n              type: 'paragraph', \n              text: 'From the associative property of convolution, instead of performing two separate convolutions — first with the Gaussian kernel and then with the finite difference filter — we can convolve the Gaussian kernel with the finite difference filter first, forming a derivative of Gaussian filter. Convolving the image directly with this filter produces the same result. This can be verified by asserting np.allclose() on the outputs of two separate convolutions and the single convolution with the derivative of Gaussian filter.'\n            },\n            { \n              type: 'math', \n              text: '\\\\((f * g) * D_x = f * (g * D_x)\\\\)'\n            },\n            { \n              type: 'paragraph', \n              text: 'Convolving with the derivative of Gaussian filters produces less noisy edge images since the Gaussian blur helps even out local variations and noise. This results in an image with more distinct edges that better outline the overall structure of the input image.'\n            },\n            {\n              type: 'image-grid',\n              columns: 2,\n              images: [\n                { title: 'Dx of Gaussian', imageUrl: '/images/dx_of_g.png' },\n                { title: 'Dy of Gaussian', imageUrl: '/images/dy_of_g.png' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Smoothed Image', imageUrl: '/images/blurred_cameraman.jpg' },\n                { title: 'Dx (Smoothed)', imageUrl: '/images/smoothed_binary_dx_of_g.jpg' },\n                { title: 'Dy (Smoothed)', imageUrl: '/images/smoothed_binary_dy_of_g.jpg' },\n                { title: 'Gradient Magnitude (Smoothed)', imageUrl: '/images/smoothed_binary_gradient_magnitude_d_of_g.jpg' },\n              ],\n            },\n          ],\n        },\n      ],\n    },\n    {\n      id: 'image-sharpening',\n      title: 'Image Sharpening Filters',\n      sections: [\n        {\n          id: 'image-sharpening-explanation',\n          title: 'Unsharp Mask Filter',\n          content: [\n            { \n              type: 'paragraph', \n              text: 'A technique to make an image sharper is to amplify the high-frequency components. This makes the image appear sharper because our visual perception tends to associate sharpness with stronger contrast in the fine details. Although the image appears sharper, it is a less accurate representation of the true image.'\n            },\n            { \n              type: 'paragraph', \n              text: 'To achieve this, we first blur the image by convolving it with a Gaussian filter. We then subtract the blurred image from the original to isolate the high-frequency components. By adding a scaled version of this high-frequency image back to the original, we obtain the sharpened result. These steps can be combined into a single convolution operation.'\n            },\n            { \n              type: 'math', \n              text: '\\\\( f + \\\\alpha (f - (f * g)) = f * ((1 + \\\\alpha)\\\\delta - \\\\alpha h) \\\\)'\n            },\n            { \n              type: 'paragraph', \n              text: 'Some examples are shown below:'\n            },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Singapore River', imageUrl: '/images/clarkequay.jpg' },\n                { title: 'Singapore River Sharpened', imageUrl: '/images/clarkequay_sharp.png' },\n                { title: 'Taj Mahal', imageUrl: '/images/taj.jpg' },\n                { title: 'Taj Mahal Sharpened', imageUrl: '/images/taj_sharp.png' },\n              ],\n            },\n            {\n              type: 'image-grid',\n              columns: 4,\n              images: [\n                { title: 'Mount Rainier', imageUrl: '/images/rainier.jpg' },\n                { title: 'Mount Rainier Sharpened', imageUrl: '/images/rainier_sharp.png' },\n                { title: 'Mount Fuji', imageUrl: '/images/fuji.png' },\n                { title: 'Mount Fuji Sharpened', imageUrl: '/images/fuji_sharp.png' },\n              ],\n            },\n            { \n              type: 'paragraph', \n              text: 'Here are more examples where an originally sharp image is blurred and then resharpened:'\n            },\n            {\n              type: 'image-grid',\n              columns: 3,\n              images: [\n                { title: 'Palacio de Cibeles', imageUrl: '/images/madrid2.jpg' },\n                { title: 'Blurred', imageUrl: '/images/madrid2_blurred.png' },\n                { title: 'Resharpened', imageUrl: '/images/madrid2_sharp.png' },\n              ],\n            },\n            { \n              type: 'paragraph', \n              text: 'The resharpened image is less sharp than the original because blurring removes the highest frequency information. Resharpening the blurred image can only amplify the remaining next highest frequency information but it cannot recover the information that is lost from blurring.'\n            },\n          ],\n        },\n      ],\n    },\n    {\n      id: 'hybrid-images',\n      title: 'Hybrid Images',\n      sections: [\n        {\n          id: 'human-perception',\n          title: 'Human Perception',\n          content: [\n            { type: 'paragraph', text: 'Different frequencies dominate human perception based on viewing distance. When viewing an image up close, the high frequencies dominiate as we tend to observe finer details. As viewing distance increases, lower frequency features such as outlines and large shapes become more prominent.' },\n            { type: 'paragraph', text: 'This gives rise to the idea of superimposing 2 images - one with high frequency elements and one with low frequency elements. This hybrid image will thus appear different based on viewing distance where the high frequency image dominates short viewing distances and the low frequency image dominates long viewing distances.' },\n          ],\n        },\n        {\n          id: 'general-approach',\n          title: 'General Approach',\n          content: [\n            { type: 'paragraph', text: 'Start with 2 images A and B. Suppose image A is the image that we want to dominate up close and image B is the one that we want to dominate from a further viewing distance. Convolve image A with a high pass filter and image B with a low pass filter. A recommended high pass filter is the impulse filter minus gaussian filer, while a recommended low pass filter is a gaussian filter. Finally, superimpose the 2 filtered images. ' },\n            {\n              type: 'math', \n              text: '\\\\(Hybrid = A * g + B * (\\\\delta - g)\\\\)'\n            }\n          ],\n        },\n        {\n          id: 'optimization',\n          title: 'Optimization',\n          content: [\n            { type: 'paragraph', text: 'It is important to maximize correlation between edges and promiment objects betweeen the 2 images - this means that the 2 images need to be well-aligned before trying to hybridize them. The uncorrelated should ideally appear as noise when seen from close/ far respectively.' },\n            { type: 'paragraph', text: 'Color can also be used to enhance the effect. Specicially, the receptors in our eyes (cones) that are responsible for observing high frequency details are also responsible for observing color. Adding color to the high frequency image while keeping the low frequency image grayscale will enhance the dominance of the high frequency image up close.'}\n          ],\n        },\n        {\n          id: 'fourier-analysis',\n          title: 'Fourier Analysis',\n          content: [\n            { type: 'paragraph', text: 'For better results, there should be a gap in the fourier response of the 2 filters to prevent them interfering with one another at the low and high spatial scales.' },\n          ],\n        },\n        {\n          id: 'results',\n          title: 'Results',\n          content: [\n            { type: 'paragraph', text: 'Content for Results section...' },\n            // Additional content...\n          ],\n        },\n      ],\n    },\n  ];\n  return (\n    <div className=\"flex min-h-screen bg-gradient-to-r from-gray-900 via-gray-800 to-black text-gray-300\">\n      <Navbar parentSections={parentSections} />\n      <div className=\"flex-1 px-4 lg:px-8 py-8 ml-64 w-full\">\n        <h1 className=\"text-4xl font-bold text-center mb-12 text-white\">Image Filters</h1>\n\n        {parentSections.map((parent) => (\n          <ParentSection\n            key={parent.id}\n            id={parent.id}\n            title={parent.title}\n            sections={parent.sections}\n          />\n        ))}\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,MAAM,MAAM,qBAAqB;AACxC,OAAOC,aAAa,MAAM,4BAA4B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvD,SAASC,GAAGA,CAAA,EAAG;EACb,MAAMC,cAAc,GAAG,CACrB;IACEC,EAAE,EAAE,eAAe;IACnBC,KAAK,EAAE,wBAAwB;IAC/BC,QAAQ,EAAE,CACR;MACEF,EAAE,EAAE,0BAA0B;MAC9BC,KAAK,EAAE,0BAA0B;MACjCE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA2V,CAAC,EACvX;QAAED,IAAI,EAAE,MAAM;QAAEC,IAAI,EAAE;MAA4K,CAAC,EACnM;QAAED,IAAI,EAAE,MAAM;QAAEC,IAAI,EAAE;MAA+G,CAAC,EACtI;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAoL,CAAC,EAChN;QAAED,IAAI,EAAE,MAAM;QAAEC,IAAI,EAAE;MAAyJ,CAAC,EAChL;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAgK,CAAC,EAC5L;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,UAAU;UAAEO,QAAQ,EAAE;QAAwB,CAAC,EACxD;UAAEP,KAAK,EAAE,IAAI;UAAEO,QAAQ,EAAE;QAA8B,CAAC,EACxD;UAAEP,KAAK,EAAE,IAAI;UAAEO,QAAQ,EAAE;QAA8B,CAAC,EACxD;UAAEP,KAAK,EAAE,oBAAoB;UAAEO,QAAQ,EAAE;QAAwC,CAAC;MAEtF,CAAC;IAEL,CAAC,EACD;MACER,EAAE,EAAE,OAAO;MACXC,KAAK,EAAE,wBAAwB;MAC/BE,OAAO,EAAE,CACP;QACEC,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,gBAAgB;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAC5D;UAAEP,KAAK,EAAE,gBAAgB;UAAEO,QAAQ,EAAE;QAAsB,CAAC;MAEhE,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,gBAAgB;UAAEO,QAAQ,EAAE;QAAgC,CAAC,EACtE;UAAEP,KAAK,EAAE,eAAe;UAAEO,QAAQ,EAAE;QAAsC,CAAC,EAC3E;UAAEP,KAAK,EAAE,eAAe;UAAEO,QAAQ,EAAE;QAAsC,CAAC,EAC3E;UAAEP,KAAK,EAAE,+BAA+B;UAAEO,QAAQ,EAAE;QAAwD,CAAC;MAEjH,CAAC;IAEL,CAAC;EAEL,CAAC,EACD;IACER,EAAE,EAAE,kBAAkB;IACtBC,KAAK,EAAE,0BAA0B;IACjCC,QAAQ,EAAE,CACR;MACEF,EAAE,EAAE,8BAA8B;MAClCC,KAAK,EAAE,qBAAqB;MAC5BE,OAAO,EAAE,CACP;QACEC,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,iBAAiB;UAAEO,QAAQ,EAAE;QAAyB,CAAC,EAChE;UAAEP,KAAK,EAAE,2BAA2B;UAAEO,QAAQ,EAAE;QAA+B,CAAC,EAChF;UAAEP,KAAK,EAAE,WAAW;UAAEO,QAAQ,EAAE;QAAkB,CAAC,EACnD;UAAEP,KAAK,EAAE,qBAAqB;UAAEO,QAAQ,EAAE;QAAwB,CAAC;MAEvE,CAAC,EACD;QACEJ,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,eAAe;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAC3D;UAAEP,KAAK,EAAE,yBAAyB;UAAEO,QAAQ,EAAE;QAA4B,CAAC,EAC3E;UAAEP,KAAK,EAAE,YAAY;UAAEO,QAAQ,EAAE;QAAmB,CAAC,EACrD;UAAEP,KAAK,EAAE,sBAAsB;UAAEO,QAAQ,EAAE;QAAyB,CAAC;MAEzE,CAAC,EACD;QACEJ,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC,EACD;QACED,IAAI,EAAE,YAAY;QAClBE,OAAO,EAAE,CAAC;QACVC,MAAM,EAAE,CACN;UAAEN,KAAK,EAAE,oBAAoB;UAAEO,QAAQ,EAAE;QAAsB,CAAC,EAChE;UAAEP,KAAK,EAAE,SAAS;UAAEO,QAAQ,EAAE;QAA8B,CAAC,EAC7D;UAAEP,KAAK,EAAE,aAAa;UAAEO,QAAQ,EAAE;QAA4B,CAAC;MAEnE,CAAC,EACD;QACEJ,IAAI,EAAE,WAAW;QACjBC,IAAI,EAAE;MACR,CAAC;IAEL,CAAC;EAEL,CAAC,EACD;IACEL,EAAE,EAAE,eAAe;IACnBC,KAAK,EAAE,eAAe;IACtBC,QAAQ,EAAE,CACR;MACEF,EAAE,EAAE,kBAAkB;MACtBC,KAAK,EAAE,kBAAkB;MACzBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAkS,CAAC,EAC9T;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAsU,CAAC;IAEtW,CAAC,EACD;MACEL,EAAE,EAAE,kBAAkB;MACtBC,KAAK,EAAE,kBAAkB;MACzBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA8a,CAAC,EAC1c;QACED,IAAI,EAAE,MAAM;QACZC,IAAI,EAAE;MACR,CAAC;IAEL,CAAC,EACD;MACEL,EAAE,EAAE,cAAc;MAClBC,KAAK,EAAE,cAAc;MACrBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAoR,CAAC,EAChT;QAAED,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAA4V,CAAC;IAE5X,CAAC,EACD;MACEL,EAAE,EAAE,kBAAkB;MACtBC,KAAK,EAAE,kBAAkB;MACzBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAsK,CAAC;IAEtM,CAAC,EACD;MACEL,EAAE,EAAE,SAAS;MACbC,KAAK,EAAE,SAAS;MAChBE,OAAO,EAAE,CACP;QAAEC,IAAI,EAAE,WAAW;QAAEC,IAAI,EAAE;MAAiC;MAC5D;MAAA;IAEJ,CAAC;EAEL,CAAC,CACF;EACD,oBACER,OAAA;IAAKY,SAAS,EAAC,sFAAsF;IAAAC,QAAA,gBACnGb,OAAA,CAACH,MAAM;MAACK,cAAc,EAAEA;IAAe;MAAAY,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eAC1CjB,OAAA;MAAKY,SAAS,EAAC,uCAAuC;MAAAC,QAAA,gBACpDb,OAAA;QAAIY,SAAS,EAAC,iDAAiD;QAAAC,QAAA,EAAC;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,EAEjFf,cAAc,CAACgB,GAAG,CAAEC,MAAM,iBACzBnB,OAAA,CAACF,aAAa;QAEZK,EAAE,EAAEgB,MAAM,CAAChB,EAAG;QACdC,KAAK,EAAEe,MAAM,CAACf,KAAM;QACpBC,QAAQ,EAAEc,MAAM,CAACd;MAAS,GAHrBc,MAAM,CAAChB,EAAE;QAAAW,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAIf,CACF,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV;AAACG,EAAA,GAzMQnB,GAAG;AA2MZ,eAAeA,GAAG;AAAC,IAAAmB,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}